{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO7HJ/u/ku/I6bKm+QpFL/2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nhyha/CodeMind_RAG/blob/main/RAG/CodeMind_RAG_V5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6eJHnj5W0Mx-"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_core.documents import Document\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.chains.query_constructor.base import AttributeInfo\n",
        "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
        "from langchain.llms import HuggingFaceHub\n",
        "\n",
        "import bs4\n",
        "from langchain import hub\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "from langchain_community.document_loaders import HuggingFaceDatasetLoader\n",
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from langchain_community.document_loaders.hugging_face_dataset import (\n",
        "    HuggingFaceDatasetLoader,\n",
        ")\n",
        "\n",
        "import streamlit as st\n",
        "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
        "from langchain.llms import HuggingFaceHub\n",
        "import os\n",
        "\n",
        "from langchain.callbacks.base import BaseCallbackHandler\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Streamlit"
      ],
      "metadata": {
        "id": "HKHNafjC1eP7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import faiss\n",
        "\n",
        "import streamlit as st\n",
        "from langchain_community.document_loaders import HuggingFaceDatasetLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain import hub\n",
        "from langchain.callbacks.base import BaseCallbackHandler\n",
        "\n",
        "from langchain.llms import HuggingFaceHub\n",
        "from langchain_openai import ChatOpenAI\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "# 환경변수 설정\n",
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] = 'your token'\n",
        "os.environ['OPENAI_API_KEY'] = 'your token'\n",
        "\n",
        "# Langsmith\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = \"your token\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"streamlit_v2\"\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "\n",
        "# 데이터 로드\n",
        "dataset_name = \"greengerong/leetcode\"\n",
        "loader = HuggingFaceDatasetLoader(dataset_name, page_content_column=\"content\")\n",
        "docs = loader.load()\n",
        "\n",
        "\n",
        "\n",
        "# 'title', 'slug', 'page_content' 결합\n",
        "for doc in docs:\n",
        "    title = doc.metadata.get('title', 'No Title') if 'title' in doc.metadata else 'No Title'\n",
        "    slug = doc.metadata.get('slug', 'No Slug') if 'slug' in doc.metadata else 'No Slug'\n",
        "    id = doc.metadata.get('id', 'No ID') if 'id' in doc.metadata else 'No ID'\n",
        "    page_content = doc.page_content\n",
        "    doc.page_content = f\"Title: {title}\\n\\nID: LeetCode_number_{id}_\\n\\nSlug: {slug}\\n\\n{page_content}\"  # 'page_content' 속성 수정\n",
        "\n",
        "# 변경된 page_content를 반영하기 위해 문서를 다시 분할\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "split_docs = text_splitter.split_documents(docs)\n",
        "\n",
        "# 변경된 문서 내용으로 벡터 스토어 및 검색 엔진 재설정\n",
        "vectorstore = FAISS.from_documents(documents=split_docs, embedding=HuggingFaceBgeEmbeddings())\n",
        "bm25_retriever = BM25Retriever.from_documents(split_docs)\n",
        "bm25_retriever.k = 20\n",
        "faiss_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 20})\n",
        "ensemble_retriever = EnsembleRetriever(retrievers=[bm25_retriever, faiss_retriever], weights=[0.1, 0.9])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class StreamCallback(BaseCallbackHandler):\n",
        "    def on_llm_new_token(self, token: str, **kwargs):\n",
        "        print(token, end=\"\", flush=True)\n",
        "\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    model_name=\"gpt-3.5-turbo\",\n",
        "    temperature=0,\n",
        "    streaming=True,\n",
        "    callbacks=[StreamCallback()],\n",
        ")\n",
        "\n",
        "\n",
        "def format_docs(docs):\n",
        "    # 검색한 문서 결과를 하나의 문단으로 합쳐줍니다.\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "prompt = hub.pull(\"nhyha/rag-prompt\")\n",
        "\n",
        "\n",
        "\n",
        "# Streamlit 인터페이스\n",
        "st.title(\"문서 검색 및 응답 생성\")\n",
        "query = st.text_input(\"질문을 입력하세요:\")\n",
        "\n",
        "# 결합된 문서 샘플 보기 기능\n",
        "if st.button(\"Show combined document samples\"):\n",
        "    st.subheader(\"Combined Document Samples:\")\n",
        "    for sample_doc in docs[:5]:  # 첫 5개의 결합된 문서 보여주기\n",
        "        st.text(sample_doc.page_content)  # 결합된 컨텐츠 출력\n",
        "        st.write(\"---\")  # 문서 사이에 구분선 추가\n",
        "\n",
        "if query:\n",
        "\n",
        "    rag_chain = (\n",
        "        {\"context\": ensemble_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "        | prompt\n",
        "        | llm\n",
        "        | StrOutputParser()\n",
        "    )\n",
        "    response = rag_chain.invoke(query)\n",
        "    st.write(\"Response:\", response)\n"
      ],
      "metadata": {
        "id": "cLee3oic0SDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken 2f9zvJxKCwgBCOHmyWDKw9FSRwQ_ufQqGCV7pvwgcKbA8zfQ"
      ],
      "metadata": {
        "id": "PEXjpKdB0wkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok http --domain=intimate-neutral-skink.ngrok-free.app"
      ],
      "metadata": {
        "id": "SOqrVDKH0w-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# 포트 8501에 대한 ngrok 터널을 설정합니다\n",
        "http_tunnel = ngrok.connect(addr=\"8501\", proto=\"http\", bind_tls=True)\n",
        "print('Streamlit이 다음 URL에서 실행 중입니다:', http_tunnel.public_url)\n",
        "\n",
        "!streamlit run app.py &>/dev/null&"
      ],
      "metadata": {
        "id": "8W38LAtC0z39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retriever 결과 확인"
      ],
      "metadata": {
        "id": "lqHSvlHR1Vr2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "\n",
        "import streamlit as st\n",
        "from langchain_community.document_loaders import HuggingFaceDatasetLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain import hub\n",
        "from langchain.callbacks.base import BaseCallbackHandler\n",
        "\n",
        "from langchain.llms import HuggingFaceHub\n",
        "from langchain_openai import ChatOpenAI\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "# 환경변수 설정\n",
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] = 'your token'\n",
        "os.environ['OPENAI_API_KEY'] = 'your token'\n",
        "\n",
        "# Langsmith\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = \"your token\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"streamlit_v2\"\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "\n",
        "# 데이터 로드\n",
        "dataset_name = \"greengerong/leetcode\"\n",
        "loader = HuggingFaceDatasetLoader(dataset_name, page_content_column=\"content\")\n",
        "docs = loader.load()\n",
        "\n",
        "\n",
        "\n",
        "# 'title', 'slug', 'page_content' 결합\n",
        "for doc in docs:\n",
        "    title = doc.metadata.get('title', 'No Title') if 'title' in doc.metadata else 'No Title'\n",
        "    slug = doc.metadata.get('slug', 'No Slug') if 'slug' in doc.metadata else 'No Slug'\n",
        "    id = doc.metadata.get('id', 'No ID') if 'id' in doc.metadata else 'No ID'\n",
        "    page_content = doc.page_content\n",
        "    doc.page_content = f\"Title: {title}\\n\\nID: LeetCode_number_{id}_\\n\\nSlug: {slug}\\n\\n{page_content}\"  # 'page_content' 속성 수정\n",
        "\n",
        "# 변경된 page_content를 반영하기 위해 문서를 다시 분할\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "split_docs = text_splitter.split_documents(docs)\n",
        "\n",
        "# 변경된 문서 내용으로 벡터 스토어 및 검색 엔진 재설정\n",
        "vectorstore = FAISS.from_documents(documents=split_docs, embedding=HuggingFaceBgeEmbeddings())\n",
        "bm25_retriever = BM25Retriever.from_documents(split_docs)\n",
        "bm25_retriever.k = 20\n",
        "faiss_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 20})\n",
        "ensemble_retriever = EnsembleRetriever(retrievers=[bm25_retriever, faiss_retriever], weights=[0.1, 0.9])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class StreamCallback(BaseCallbackHandler):\n",
        "    def on_llm_new_token(self, token: str, **kwargs):\n",
        "        print(token, end=\"\", flush=True)\n",
        "\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    model_name=\"gpt-3.5-turbo\",\n",
        "    temperature=0,\n",
        "    streaming=True,\n",
        "    callbacks=[StreamCallback()],\n",
        ")\n",
        "\n",
        "def format_docs(docs):\n",
        "    # 검색한 문서 결과를 하나의 문단으로 합쳐줍니다.\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "prompt = hub.pull(\"nhyha/rag-prompt\")\n"
      ],
      "metadata": {
        "id": "21Zzji601cV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 단계 8: 체인 생성(Create Chain)\n",
        "rag_chain = (\n",
        "    {\"context\": ensemble_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "# question = \"Please write example code to solve the problem of minimum-window-substring.\"\n",
        "# question = \"Please write example code to solve the problem of Integer to Roman\"\n",
        "question = \"Please write example code to solve the problem of Find the Index of the First Occurrence in a String\"\n",
        "\n",
        "response = rag_chain.invoke(question)\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"Dataset Path: {dataset_name}\")\n",
        "print(f\"문서의 수: {len(split_docs)}\")\n",
        "print(\"===\" * 20)\n",
        "print(f\"[HUMAN]\\n{question}\\n\")\n",
        "print(f\"[AI]\\n{response}\")"
      ],
      "metadata": {
        "id": "2uvs5QpQ1sRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_retriever.invoke(\"i dont know about word break problem. please give me an approch about this problem in python.\")"
      ],
      "metadata": {
        "id": "PAJuDool1xYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_retriever.invoke(\"Please write example code to solve the problem of Find the Index of the First Occurrence in a String\")"
      ],
      "metadata": {
        "id": "b7Jor1ac1zO0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}